<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Optimization &#183; Blog of gigio1023</title>
<meta name=title content="Optimization &#183; Blog of gigio1023"><meta name=description content="부캠 강사님께서 용어에 대해 확실히 알고 가라고 하셨다.어제(21.08.09) 선택과제 2번의 AAE에 대해서 알아보다가 기겁을 했다. 한 문장 안에서 모르는 단어를 세는 것보다, 아는 단어를 세는게 빨랐다. 분명 영어로 쓰여있는데 외계어 같았다... 인턴을 하면서, "><meta name=keywords content="DL,optimization,"><link rel=canonical href=https://gigio1023.github.io/posts/ml/2021-08-10-optimization/><link type=text/css rel=stylesheet href=/css/main.bundle.min.930a7c6a69224a9dc067fbe56035893295d7d83b892c265af91a4fa70d5428caf70cd14538bd83dfa4a867905c07bfd20884f698d9be1127676af1de53796eff.css integrity="sha512-kwp8amkiSp3AZ/vlYDWJMpXX2DuJLCZa+RpPpw1UKMr3DNFFOL2D36SoZ5BcB7/SCIT2mNm+ESdnavHeU3lu/w=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.b6411b5d4cd56c0068d34c4acbce043846adad56b824e3d486a06d3459aed2eb7f7413874b7871cc2c822c8c8834cbed944022918bcc8cca710a962167c36d32.js integrity="sha512-tkEbXUzVbABo00xKy84EOEatrVa4JOPUhqBtNFmu0ut/dBOHS3hxzCyCLIyINMvtlEAikYvMjMpxCpYhZ8NtMg==" data-copy data-copied></script><script src=/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://gigio1023.github.io/posts/ml/2021-08-10-optimization/"><meta property="og:site_name" content="Blog of gigio1023"><meta property="og:title" content="Optimization"><meta property="og:description" content="부캠 강사님께서 용어에 대해 확실히 알고 가라고 하셨다.어제(21.08.09) 선택과제 2번의 AAE에 대해서 알아보다가 기겁을 했다. 한 문장 안에서 모르는 단어를 세는 것보다, 아는 단어를 세는게 빨랐다. 분명 영어로 쓰여있는데 외계어 같았다... 인턴을 하면서,"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-08-10T01:35:15+00:00"><meta property="article:modified_time" content="2021-08-10T01:35:15+00:00"><meta property="article:tag" content="DL"><meta property="article:tag" content="Optimization"><meta name=twitter:card content="summary"><meta name=twitter:title content="Optimization"><meta name=twitter:description content="부캠 강사님께서 용어에 대해 확실히 알고 가라고 하셨다.어제(21.08.09) 선택과제 2번의 AAE에 대해서 알아보다가 기겁을 했다. 한 문장 안에서 모르는 단어를 세는 것보다, 아는 단어를 세는게 빨랐다. 분명 영어로 쓰여있는데 외계어 같았다... 인턴을 하면서,"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"Optimization","headline":"Optimization","description":"부캠 강사님께서 용어에 대해 확실히 알고 가라고 하셨다.어제(21.08.09) 선택과제 2번의 AAE에 대해서 알아보다가 기겁을 했다. 한 문장 안에서 모르는 단어를 세는 것보다, 아는 단어를 세는게 빨랐다. 분명 영어로 쓰여있는데 외계어 같았다... 인턴을 하면서, ","inLanguage":"en","url":"https:\/\/gigio1023.github.io\/posts\/ml\/2021-08-10-optimization\/","author":{"@type":"Person","name":"Sungho Park"},"copyrightYear":"2021","dateCreated":"2021-08-10T01:35:15\u002b00:00","datePublished":"2021-08-10T01:35:15\u002b00:00","dateModified":"2021-08-10T01:35:15\u002b00:00","keywords":["DL","optimization"],"mainEntityOfPage":"true","wordCount":"1218"}]</script><meta name=author content="Sungho Park"><link href=mailto:relilau00@gmail.com rel=me><link href=https://gigio1023.github.io/ rel=me><link href=https://www.linkedin.com/in/gigio1023/ rel=me><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><meta name=theme-color></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">Blog of gigio1023</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=Posts>Blog</p></a><a href=https://github.com/gigio1023 target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span class=mr-1><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title>GitHub</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-1 rtl:ml-1"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=Posts>Blog</p></a></li><li class=mt-1><a href=https://github.com/gigio1023 target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div class=mr-2><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title>GitHub</p></a></li></ul></div></label></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Optimization</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2021-08-10T01:35:15+00:00>10 August 2021</time><span class="px-2 text-primary-500">&#183;</span><span>1218 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">6 mins</span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Sungho Park" src=/img/blowfish_logo_hu_e74a130226122ae3.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Sungho Park</div><div class="text-sm text-neutral-700 dark:text-neutral-400">To build a genuinely useful product</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=mailto:relilau00@gmail.com target=_blank aria-label=Email rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://gigio1023.github.io/ target=_blank aria-label=Link rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://www.linkedin.com/in/gigio1023/ target=_blank aria-label=Linkedin rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/eb1d4749-f4b0-4545-a5a8-e2b72b35b6e4-image.png alt></figure></p><p>부캠 강사님께서 용어에 대해 확실히 알고 가라고 하셨다.</p><p>어제(21.08.09) 선택과제 2번의 AAE에 대해서 알아보다가 기겁을 했다. 한 문장 안에서 모르는 단어를 세는 것보다, 아는 단어를 세는게 빨랐다. 분명 영어로 쓰여있는데 외계어 같았다&mldr;</p><p>인턴을 하면서, 졸업프로젝트를 하면서 혼자 독학으로 잡다하게 지식을 쌓아올린 폐해라고 생각한다. ML 분야에서 사용되는 용어들만이라도 확실하게 알고 있자.</p><p>그런 의미로 알고 있던 용어들이라도 수업에서 다뤘던 것들은 모두 기술했다.</p><h1 class="relative group">Introduction<div id=introduction class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#introduction aria-label=Anchor>#</a></span></h1><h2 class="relative group">Gradient descent<div id=gradient-descent class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#gradient-descent aria-label=Anchor>#</a></span></h2><p>undefined</p><p>First-order iterative optimization algorithm for finding a <em><strong>local minimum</strong></em> of a differentiable function.</p><h1 class="relative group">Hyper parameter<div id=hyper-parameter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#hyper-parameter aria-label=Anchor>#</a></span></h1><p>parameter : 가중치, bias, convolution weight 등 학습이 되면서 업데이트 되는 것들.
hyper parameter : learning rate, network의 크기, loss function의 종류 등 개발자가 직접 정하는 것들.</p><h1 class="relative group">Generalization<div id=generalization class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#generalization aria-label=Anchor>#</a></span></h1><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/8103a09e-337e-491f-b114-41fb50a6509d-image.png alt></figure>보통 학습이 오래 지속되면 test error는 증가한다.
train과 test 사이의 성능 gap을 Generalizaiton gap이라고 한다.</p><p>Generalization performance가 좋다.
= 모델의 성능이 학습 데이터를 사용했을 때와 비슷함을 보장.</p><p>하지만, Generalization performance가 좋다고 모델의 성능이 좋음을 보장하지는 않는다.
왜냐하면 학습 데이터가 제대로 학습되지 않은 모델임에도 Generalization performance는 좋을 수 있기 때문이다.</p><h1 class="relative group">Underfitting, Overfitting<div id=underfitting-overfitting class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#underfitting-overfitting aria-label=Anchor>#</a></span></h1><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/f4e80d54-ae70-4a91-ad57-13e820a06b90-image.png alt></figure>Overfitting(과적합) : 학습 데이터에서는 모델이 잘 작동하지만, 실제 성능은 좋지 않은 것.
Underfitting : 학습이 제대로 되지 않아, 학습조차 제대로 안된 것.</p><p>물론, 위 그림은 concept만을 명시한 것이다. 즉, Overfitting의 예시 도표가 실제로는 우리가 원하는 결과일 때도 분명 존재한다는 것이다. 문제의 정의, 도메인 지식 등 여러가지를 살려서 판단하자.</p><h1 class="relative group">Cross-validation<div id=cross-validation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#cross-validation aria-label=Anchor>#</a></span></h1><p>K-fold validation.<figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/17d78872-bc7f-4489-9fef-4fbfd39ce8ad-image.png alt></figure>ref: <a href=https://blog.quantinsti.com/cross-validation-machine-learning-trading-models/ target=_blank>https://blog.quantinsti.com/cross-validation-machine-learning-trading-models/</a></p><ol><li>train data를 k개로 구분한다.</li><li>k-1개를 train에 사용한다.</li><li>나머지 1개를 validation에 사용한다.</li></ol><hr><p>hyper parameter에 대한 clue는 보통 없다! 그래서 cross validation을 통해 최적의 hyper parameter 조합을 찾는다.</p><p>최적의 hyper parameter를 찾으면, hyper parameter를 고정 후 모든 학습 데이터를 활용해 학습한다.</p><p>당연하지만 test data는 어떠한 방식으로든 학습에서 활용하면 안된다. 엄연히 cheating과도 같은 행위이다. 물론 cheating을 한다고 좋은 모델을 만든다고 보장할 수도 없다.</p><h1 class="relative group">Bias, Variance<div id=bias-variance class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#bias-variance aria-label=Anchor>#</a></span></h1><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/16924af4-30e6-4ea1-b216-34fb72413392-image.png alt></figure>ref : <a href=https://work.caltech.edu/telecourse target=_blank>https://work.caltech.edu/telecourse</a></p><p>탄착군이랑 똑같이 생각하자.
<strong>Variance</strong></p><ul><li>입력에 대해 출력이 얼마나 일관적인지를 의미.</li><li>낮을수록 일관적이다.</li><li>높을수록 일관적이지 않다.</li></ul><p><strong>Bias</strong></p><ul><li>원하고자 하는 값과 얼마나 떨어져 있는지</li></ul><h2 class="relative group">Bias and Variance Tradeoff<div id=bias-and-variance-tradeoff class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#bias-and-variance-tradeoff aria-label=Anchor>#</a></span></h2><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/c50f856f-580f-4562-b70d-ac7dc0d2137d-image.png alt></figure>학습 데이터에 노이즈가 끼어 있다고 가정할 한다.
We can derive that what we are minimizing(cost) can be decomposed into three different parts: $$bias^2$$, $$variance$$, and $$noise$$.</p><p>즉, 내가 minimize하는 값은 한가지 값이지만 그 값은 3가지 component이다. 또한 3가지 component는 무언가가 작아지면, 무언가가 커지는 trade-off 관계이다.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/f5938e91-b533-4b4b-ae4d-210b8257c844-image.png alt></figure></p><p>즉, cost를 위와 같이 3가지 term으로 구분해서 생각할 수 있는 것이다.
보통 bias와 variance가 trade-off라고 한다.</p><h1 class="relative group">Bootstrapping<div id=bootstrapping class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#bootstrapping aria-label=Anchor>#</a></span></h1><p>통계학에서 사용되는 용어.
Bootstrapping is any test or metric that uses random sampling with replacement.</p><p>가령 100개의 학습데이터에 대해서 무작위로 80개씩 추출하는 행위를 통해 여러 개의 모델 configuration을 만들어 서로 비교할 때 사용한다.</p><h1 class="relative group">Bagging, Boosting<div id=bagging-boosting class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#bagging-boosting aria-label=Anchor>#</a></span></h1><p><strong>Bagging(Boostrapping aggregating)</strong></p><ul><li>eg. Bootstrapping을 통해 학습 데이터를 여러개로 subsampling한다. 여러개의 학습 데이터별로 서로 다른 모델의 output이 발생하고 이를 활용한다. (통계값을 추출하거나 앙상블 학습을 하거나 등등)</li></ul><p>전체 학습 데이터를 하나의 모델에 대해 한번만 학습해 하나의 결과를 추출하는 것보다 더 좋은 성능을 보여주는 경우가 대부분이다.
Kaggle같은 대회에서 대표적으로 사용되는 기법이다.</p><p><strong>Boosting</strong>
가령 학습을 할 때, 80개의 데이터에 대해서는 분류가 잘 되지만 나머지 20개의 데이터에 대해서는 분류가 잘 안된다고 가정해보자.
나머지 20개에 대해서는 별도의 모델을 생성해서 학습을 한다. 이러한 방식으로 만들어진 모델을 weak learner라고 하자.</p><p>이러한 weak learners를 sequence하게 묶어서 <strong>하나의 strong learner</strong>를 만든다. boosting에서는 weak learner들의 weight들을 sequence하게 학습한다.</p><hr><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/cf306c62-c333-47c2-a8b5-fa543644371f-image.png alt></figure></p><h1 class="relative group">Practical Gradient Descent Method<div id=practical-gradient-descent-method class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#practical-gradient-descent-method aria-label=Anchor>#</a></span></h1><ul><li>Stochastic gradient descent<ul><li>한번에 하나의 데이터만을 사용해 parameter 업데이트.</li></ul></li><li>mini-batch gradient descent<ul><li>한번에 subset 데이터만을 사용해 parameter 업데이트.</li></ul></li><li>batch gradient descent<ul><li>모든 데이터를 한번에 활용</li></ul></li></ul><h2 class="relative group">Batch size matters<div id=batch-size-matters class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#batch-size-matters aria-label=Anchor>#</a></span></h2><blockquote></blockquote><p>We .. present numerical evidence that supports the view that large batch methods tend to converge to <em><strong>sharp minimizers</strong></em> of the training and testing functions.
In constrast, small-batch methods consistently converge to <em><strong>flat minimizers</strong></em>&mldr; this is due to the inherent noise in the gradient estimation.</p><p>해당 논문에서 large batch method는 sharp minimizer를, small-batch method는 flat minimizer를 가진다고 한다. 이에 대한 설명은 아래 그래프와 같다.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/7fb85c2e-6ad7-47f1-a1f4-6b591a789586-image.png alt></figure>ref: <a href=https://arxiv.org/pdf/1609.04836.pdf target=_blank>https://arxiv.org/pdf/1609.04836.pdf</a> (ON LARGE-BATCH TRAINING FOR DEEP LEARNING:
GENERALIZATION GAP AND SHARP MINIMA)</p><p>flat minimum : test function과 training function이 멀더라도, 어느정도 학습이 된다. <em><strong>Generalization performance가 높다!</strong></em>
sharp minimum : Geenralization performance가 낮다.</p><h2 class="relative group">Gradient descent methods<div id=gradient-descent-methods class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#gradient-descent-methods aria-label=Anchor>#</a></span></h2><h3 class="relative group">(Stochastic) Gradient descent<div id=stochastic-gradient-descent class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#stochastic-gradient-descent aria-label=Anchor>#</a></span></h3><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/ad76fb47-36fb-40e0-bf9b-48875a2b8b44-image.png alt></figure>너무나도 익숙한 기본적인 Gradient descent의 parameter update 수식이다.</p><p>문제점 : η(learning rate)를 잡는 것이 어렵다. 너무 작으면 학습 진행이 안되고, 너무 크면 학습이 제대로 안된다.</p><h3 class="relative group">Momentum<div id=momentum class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#momentum aria-label=Anchor>#</a></span></h3><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/4a286162-7a9a-405a-94eb-0a9a13a41fac-image.png alt></figure></p><p>말 그대로 Momentum(관성)을 유지하면서 parameter를 업데이트한다.
β(momentum)은 hyper parameter이다. β와 gradient, 이전 step의 accumulation을 통해 새로운 accumulation을 얻는다.
이를 통해 이전 step에서 사용된 정보를 SGD처럼 모두 버리지 않고, 어느 정도 유지하면서 W를 업데이트한다.</p><h3 class="relative group">Nesterov Accelerated Gradient(NAG)<div id=nesterov-accelerated-gradientnag class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#nesterov-accelerated-gradientnag aria-label=Anchor>#</a></span></h3><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/89fade6f-4c7b-495e-b249-28259512df4d-image.png alt></figure></p><p>수식의 큰 틀은 momentum과 같다. 다른 점은 다음 스텝의 graident를 미리 계산해보고 이렇게 계산된 Lookahead gradient를 활용해 accumulation을 업데이트한다.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/6c02f42a-d117-412d-bbcb-d288e3560adb-image.png alt></figure></p><p>ref: <a href=https://golden.com/wiki/Nesterov_momentum target=_blank>https://golden.com/wiki/Nesterov_momentum</a></p><p>Moementum과 Nesterov momentum은 위 그림과 같은 차이가 있다. 직관적으로 이해해보면, momentum은 converge point에 한번에 수렴하지 못하고 진자마냥 움직이면서 수렴을 하지 못하는 경우가 생긴다.</p><p>Nesterov는 다음 step의 gradient를 활용해 업데이트하기 때문에, 한쪽 방향으로만 가는 효과가 있다. 따라서 NAG가 보통 좀더 빨리 converge한다.</p><h3 class="relative group">Adagrad<div id=adagrad class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#adagrad aria-label=Anchor>#</a></span></h3><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/4257e2a2-df6a-483b-a1f0-49551601497f-image.png alt></figure></p><p>parameter가 지금까지 얼마나 많이 변화했는지를 업데이트에 반영한다.
$$G_t$$는 sum of gradient squares다. 즉, parameter가 많이 변화했으면 $$G_t$$가 커지므로 parameter는 적게 변화한다. parametert가 적게 변화했으면 $$G_t$$가 작으므로 parameter는 크게 변화한다.</p><p>$$\epsilon$$은 zero division을 방지하기 위해 들어갔다.</p><p>문제점
$$G_t$$가 무한정 커질 수 있다. 즉, 분모가 무한대가 되면서 해당 항이 0에 수렴하게 된다. parameter가 더 이상 업데이트 되지 않는 문제점이 발생한다.</p><h3 class="relative group">Adadelta<div id=adadelta class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#adadelta aria-label=Anchor>#</a></span></h3><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/f751a440-d120-440c-a6ab-de5e67be655a-image.png alt></figure></p><p>Window size만큼의 시간동안 gradient의 변화만을 보는 방법론이다.</p><p>문제는 $$g_t$$의 parameter가 모델의 parameter 개수만큼 존재해야하는 것이다. model의 parameter는 개별적으로 하나의 gradient를 가지기 때문이다. 그렇다면 GPT3와 같은 대형모델에서 천억개의 parameter를 가진다고 하면, $$g_t$$ 또한 천억개의 parameter에 대한 gradient정보를 windows size만큼 가지고 있어야한다.</p><p>이를 해결하기 위해 exponential moving average(EMA, 이동평균)을 사용한다. 위 수식에서 $$\gamma$$를 사용한 방식이라고 한다&mldr;(?)</p><p><em><strong>learning rate가 없다!</strong></em>
= hyper parameter를 변경할 수 있는 여지가 없다. 따라서 실용적으로 활용되지는 않는다.</p><h3 class="relative group">RMSprop<div id=rmsprop class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#rmsprop aria-label=Anchor>#</a></span></h3><p>논문으로 발표된 방식은 아니고, Geoff Hinton이 강의 중에 공개한 optimzation. 실제로 논문들이 RMSprop을 사용할 때, Geoff Hinton의 lecture link를 citation했다고 한다.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/57e8d39b-5fe2-4175-966b-ad329e4b5863-image.png alt></figure></p><h3 class="relative group">Adam(Adaptive Moment Estimation)<div id=adamadaptive-moment-estimation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#adamadaptive-moment-estimation aria-label=Anchor>#</a></span></h3><p>past graidents(momentum)과 squared gradients(Adagrad, RMSprop&mldr;)을 합친 것.
즉, momentum 정보와 adaptive learning rate 방식을 혼용한 것.<figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/b1919bc5-0605-4143-9766-9b7fb568fc5f-image.png alt></figure></p><p>4개의 hyper paramter를 조정하는 것도 매우매우 중요하다.</p><ul><li>$$\epsilon$$ : 매우 작은 값</li><li>$$\beta_1$$ : momentum</li><li>$$\beta_2$$ : graident squares</li><li>$$\eta$$ : learning rate</li></ul><h1 class="relative group">Regularization<div id=regularization class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#regularization aria-label=Anchor>#</a></span></h1><p>학습을 규제, 방해해서 학습데이터에서만 모델이 잘 작동하는 것이 아니라, 테스트 데이터에서도 잘 작동하도록 하는 것이 목적.</p><h2 class="relative group">Early stopping<div id=early-stopping class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#early-stopping aria-label=Anchor>#</a></span></h2><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/40d7d36e-b662-4271-99b8-e08ddbb8717f-image.png alt></figure>test data가 아닌 validation data를 활용해, 적절하게 멈추는 시점을 정한다.</p><h2 class="relative group">Parameter Norm Penalty<div id=parameter-norm-penalty class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#parameter-norm-penalty aria-label=Anchor>#</a></span></h2><p>parameter의 크기가 커지지 않게 하는 것.<figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/77786af1-ff49-457e-b5da-5c96dfcad47f-image.png alt></figure></p><p>total cost를 작게 하는 방향으로 학습하자.</p><p>함수 공간 내에서 함수를 되도록 부드럽게 만들자.(?) 라고 강사님이 말씀하셨는데 무슨 말인지 모르겠다..</p><p>parameter norm penalty를 weight decay라고 부르기도 한다.</p><h2 class="relative group">Data Augmentation<div id=data-augmentation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#data-augmentation aria-label=Anchor>#</a></span></h2><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/db61a2e2-a892-45e0-aafb-47966822162f-image.png alt></figure>DL, NN은 전통적인 ML과 다르게 데이터가 많으면 많을수록 좋다. 그래서 이미지를 뻥튀기하듯이 데이터를 많이 생성하면 되도록 좋다.</p><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/fb429d9f-2c90-4788-b5c1-b59d0b9fa551-image.png alt></figure></p><p>위 그림과 같이 이미지의 크기, 기울기, crop 정도를 변화하면서 data를 늘린다. 단, 라벨은 고정되어야한다.</p><h2 class="relative group">Noise Robustness<div id=noise-robustness class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#noise-robustness aria-label=Anchor>#</a></span></h2><p>입력 데이터와 weight에 noise를 넣어주어 학습하면 테스트 단계에서 더욱 잘 작동한다.
완벽하게 증명은 안됐지만, 실험적으로는 증명됨.<figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/3b107bac-9e6b-47ac-b6b4-f2e14cf846df-image.png alt></figure></p><h2 class="relative group">Label Smoothing<div id=label-smoothing class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#label-smoothing aria-label=Anchor>#</a></span></h2><p>학습 단계에서 학습 데이터 두 개를 추출해 섞어서 새로운 학습 데이터를 생성.
Decision boundary를 부드럽게 만들어주는 효과가 있다고 한다.</p><p><em><strong>모델의 성능을 매우매우 잘 올릴 수 있는 방법론이다!</strong></em></p><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/3cda6bbf-463c-4b3c-b07f-6fb7a9f87f56-image.png alt></figure></p><p>ref: <a href=https://arxiv.org/pdf/1905.04899.pdf target=_blank>https://arxiv.org/pdf/1905.04899.pdf</a> (CutMix: Regularization Strategy to Train Strong Classifiers
with Localizable Features)</p><p>Mixup : 두 개의 이미지와 라벨을 섞는다.
Cutout : 이미지의 일정 부분을 제거
CutMix : Mixup과 다르게 잘라서 섞는다.</p><h2 class="relative group">Dropout<div id=dropout class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#dropout aria-label=Anchor>#</a></span></h2><p>랜덤하게 일부 뉴런을 0으로 만들어준다.<figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/24be1ed4-61c5-4cc7-8dd5-253b56c5398e-image.png alt></figure>뉴런들이 좀더 robust한 feature를 가진다고 해석한다. 이 또한 증명은 없다.</p><h2 class="relative group">Batch Normalization<div id=batch-normalization class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#batch-normalization aria-label=Anchor>#</a></span></h2><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/8517c386-b451-4779-af90-2171c3e89dce-image.png alt></figure></p><p>layer별로 weight들의 mean과 variance를 활용해 weight를 normalize한다. 위 수식처럼 mean을 빼고 variance로 나눠줘서 새로운 weight를 구한다.</p><p>논문에서는 이러한 행위가 Internal covariate shift를 줄이기에 성능이 향상된다고 해석했는데, 여러 반박 논문들이 있다고 한다..</p><p>확실한 것은 BN을 사용하면 Network가 깊어질수록 사용하지 않을 때보다 성능이 많이 좋아진다.</p><hr><p><figure><img class="my-0 rounded-md" loading=lazy src=/assets/images/Optimization/5124757b-893f-4e43-868d-d0189b23ecb6-image.png alt></figure></p><p>BN과 비슷한 방법론들이 있다. 적절하게 사용하자.</p></div></div><script>var oid="views_posts/ML/2021-08-10-Optimization.md",oid_likes="likes_posts/ML/2021-08-10-Optimization.md"</script><script type=text/javascript src=/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/posts/old_postings/2021-08-09-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">데이터 시각화</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2021-08-09T13:06:49+00:00>9 August 2021</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/posts/ml/2021-08-10-optimizer-%EC%8B%A4%EC%8A%B5/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Optimizer 실습</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2021-08-10T07:58:31+00:00>10 August 2021</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Sungho Park</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://gigio1023.github.io/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>