<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Word Embedding &#183; Blog of gigio1023</title>
<meta name=title content="Word Embedding &#183; Blog of gigio1023"><meta name=description content="문장의 단어들을 벡터 공간 상의 점으로 표현하기 위해, 단어들을 벡터로 변환하는 방법.Word Embedding 자체가 딥러닝, 머신러닝 기술이다. 학습 데이터, 사전에 정의한 벡터 공간의 차원 수를 통해 핛브을 진행한다. 학습이 완료되면 학습 데이터, 즉 특정 단어에"><meta name=keywords content="NLP,"><link rel=canonical href=https://gigio1023.github.io/posts/ml/2021-09-06-word-embedding/><link type=text/css rel=stylesheet href=/css/main.bundle.min.e96772c5cdc14f53dc8f2d49a7f91bd1dc21484251faa988567a4cb5313e24ea6befb15bbad2f816721b267c196c83c5c688647f3f59faf0e25b638d0e602880.css integrity="sha512-6Wdyxc3BT1Pcjy1Jp/kb0dwhSEJR+qmIVnpMtTE+JOpr77FbutL4FnIbJnwZbIPFxohkfz9Z+vDiW2ONDmAogA=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.b6411b5d4cd56c0068d34c4acbce043846adad56b824e3d486a06d3459aed2eb7f7413874b7871cc2c822c8c8834cbed944022918bcc8cca710a962167c36d32.js integrity="sha512-tkEbXUzVbABo00xKy84EOEatrVa4JOPUhqBtNFmu0ut/dBOHS3hxzCyCLIyINMvtlEAikYvMjMpxCpYhZ8NtMg==" data-copy data-copied></script><script src=/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://gigio1023.github.io/posts/ml/2021-09-06-word-embedding/"><meta property="og:site_name" content="Blog of gigio1023"><meta property="og:title" content="Word Embedding"><meta property="og:description" content="문장의 단어들을 벡터 공간 상의 점으로 표현하기 위해, 단어들을 벡터로 변환하는 방법.Word Embedding 자체가 딥러닝, 머신러닝 기술이다. 학습 데이터, 사전에 정의한 벡터 공간의 차원 수를 통해 핛브을 진행한다. 학습이 완료되면 학습 데이터, 즉 특정 단어에"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-09-06T11:04:54+00:00"><meta property="article:modified_time" content="2021-09-06T11:04:54+00:00"><meta property="article:tag" content="NLP"><meta name=twitter:card content="summary"><meta name=twitter:title content="Word Embedding"><meta name=twitter:description content="문장의 단어들을 벡터 공간 상의 점으로 표현하기 위해, 단어들을 벡터로 변환하는 방법.Word Embedding 자체가 딥러닝, 머신러닝 기술이다. 학습 데이터, 사전에 정의한 벡터 공간의 차원 수를 통해 핛브을 진행한다. 학습이 완료되면 학습 데이터, 즉 특정 단어에"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"Word Embedding","headline":"Word Embedding","description":"문장의 단어들을 벡터 공간 상의 점으로 표현하기 위해, 단어들을 벡터로 변환하는 방법.Word Embedding 자체가 딥러닝, 머신러닝 기술이다. 학습 데이터, 사전에 정의한 벡터 공간의 차원 수를 통해 핛브을 진행한다. 학습이 완료되면 학습 데이터, 즉 특정 단어에","inLanguage":"en","url":"https:\/\/gigio1023.github.io\/posts\/ml\/2021-09-06-word-embedding\/","author":{"@type":"Person","name":"Sungho Park (gigio1023)"},"copyrightYear":"2021","dateCreated":"2021-09-06T11:04:54\u002b00:00","datePublished":"2021-09-06T11:04:54\u002b00:00","dateModified":"2021-09-06T11:04:54\u002b00:00","keywords":["NLP"],"mainEntityOfPage":"true","wordCount":"874"}]</script><meta name=author content="Sungho Park (gigio1023)"><link href=mailto:relilau00@gmail.com rel=me><link href=https://gigio1023.github.io/ rel=me><link href=https://www.linkedin.com/in/gigio1023/ rel=me><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><meta name=theme-color></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">Blog of gigio1023</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=Posts>Blog</p></a><a href=/categories/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=Categories>Categories</p></a><a href=https://github.com/gigio1023 target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span class=mr-1><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title>GitHub</p></a><a href=/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=Tags>Tags</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-1 rtl:ml-1"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=Posts>Blog</p></a></li><li class=mt-1><a href=/categories/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=Categories>Categories</p></a></li><li class=mt-1><a href=https://github.com/gigio1023 target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div class=mr-2><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title>GitHub</p></a></li><li class=mt-1><a href=/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=Tags>Tags</p></a></li></ul></div></label></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Word Embedding</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2021-09-06T11:04:54+00:00>6 September 2021</time><span class="px-2 text-primary-500">&#183;</span><span>874 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">5 mins</span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="Sungho Park (gigio1023)" src=/img/profile_hu_bc5ec457e77a1933.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Sungho Park (gigio1023)</div><div class="text-sm text-neutral-700 dark:text-neutral-400">To build a genuinely useful product</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=mailto:relilau00@gmail.com target=_blank aria-label=Email rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://gigio1023.github.io/ target=_blank aria-label=Link rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://www.linkedin.com/in/gigio1023/ target=_blank aria-label=Linkedin rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><h1 class="relative group">Word Embedding<div id=word-embedding class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#word-embedding aria-label=Anchor>#</a></span></h1><p>문장의 단어들을 벡터 공간 상의 점으로 표현하기 위해, 단어들을 벡터로 변환하는 방법.</p><p>Word Embedding 자체가 딥러닝, 머신러닝 기술이다. 학습 데이터, 사전에 정의한 벡터 공간의 차원 수를 통해 학습을 진행한다. 학습이 완료되면 학습 데이터, 즉 특정 단어에 대한 최적의 벡터를 출력해준다.</p><h2 class="relative group">Word Embedding의 기본 아이디어<div id=word-embedding%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EC%95%84%EC%9D%B4%EB%94%94%EC%96%B4 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#word-embedding%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EC%95%84%EC%9D%B4%EB%94%94%EC%96%B4 aria-label=Anchor>#</a></span></h2><p>비슷한 의미를 가지는 단어들이 벡터 공간에서 비슷한 위치에 맵핑되게 하여 유사도를 가지게 한다. 이를 통해 다른 자연어 처리에서 더욱 쉽게 task를 처리하도록 환경을 제공한다.</p><h2 class="relative group">Word2Vec<div id=word2vec class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#word2vec aria-label=Anchor>#</a></span></h2><p>Word Embedding의 대표적인 예시이다.</p><p>하나의 문장에서 인접한 단어들은 비슷한 의미를 가질 것이라는 가정이 이 알고리즘의 기본 아이디어다. 즉, _<strong>특정 단어는 주변의 단어들을 통해 해당 단어의 의미를 알 수 있다</strong>_는 논리가 존재하는 알고리즘이다.</p><blockquote><p>The cat purrs.
This cat hunts mice.</p></blockquote><p>위 두 문장에서 cat 주변에는 The, purrs, this, hunts, mice가 있다. 그렇다면 이 단어들은 cat과 유사한 의미를 가질 것이라는 가정이 존재하는 것이다.</p><h3 class="relative group">예측 방법<div id=%EC%98%88%EC%B8%A1-%EB%B0%A9%EB%B2%95 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%EC%98%88%EC%B8%A1-%EB%B0%A9%EB%B2%95 aria-label=Anchor>#</a></span></h3><p>학습데이터를 바탕으로 target 단어(여기서는 cat) 주변 단어들(w)의 확률 분포를 예측한다.</p><p>![](/assets/images/Word Embedding/86cb5366-3ede-449e-ad8a-7cabfc970947-image.png)
만약 cat이 입력으로 주어졌다면, 주변 단어를 숨기고 $P(w|cat)$의 학습을 진행한다.</p><h3 class="relative group">학습 방법<div id=%ED%95%99%EC%8A%B5-%EB%B0%A9%EB%B2%95 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%ED%95%99%EC%8A%B5-%EB%B0%A9%EB%B2%95 aria-label=Anchor>#</a></span></h3><ol><li>주어진 문장을 word로 분리하는 Tokenization을 수행.</li><li>Unique words로 vocabulary 구축.</li><li>Vocabulary의 각 단어들은 Vocabulary의 사이즈만큼의 dimension을 가지는 One-hot vector로 나타낸다.</li><li>Sliding windows를 통해 학습 데이터의 입출력 쌍을 구성한다.</li></ol><p>가령 Sliding windows의 크기가 3이라고 해보자.</p><blockquote><p>I study math.</p></blockquote><p>해당 문장에서 I에 Sliding windows를 적용한다면, I를 기준으로 앞뒤로 1개의 단어들을 살펴본다. 앞에는 아무 단어가 없고, 뒤에 study가 있으므로 I를 기준으로는 (I, study)라는 입출력 쌍이 구성된다.</p><p>study를 기준으로 한다면 앞뒤로 I와 math가 있다. 그러므로 (study, I), (study, math)라는 입출력 쌍이 구성된다.</p><ol start=5><li>간단한 neural network를 구성해서 준비된 쌍들을 학습한다.</li></ol><p>![](/assets/images/Word Embedding/a55dc671-1420-4c7f-bd74-a6232bf7aa48-image.png)</p><p>Input Layer: 입력 one-hot vecotor의 차원 수만큼의 node를 가진다.
Output Layer: 출력 one-hot vecotor의 차원 수만큼의 node를 가진다.
Hiddne Layer: Word embedding을 수행하는 좌표 공간의 차원수와 동일하게 node를 구성. 사용자가 설정하는 hyperparameter.</p><hr><p>![](/assets/images/Word Embedding/f3a03d57-9baa-4a28-aa9d-7c3cf21eea57-image.png)</p><p>위 neural network를 벡터로 도식화하면 위와 같다.</p><p>$W_2(W_1x)$의 형태로 곱할 것이기 때문에 W1은 (2,3,), W2는 (3,2)로 구성한다. 그 후 softmax를 통과시켜서 3차원 벡터가 확률분포를 가지도록 바꿔준다. 이렇게 구한 출력 값과 y 벡터 간의 거리가 가장 가까워지도록 neural network를 학습하기 위해 softmax loss를 사용한다.</p><h3 class="relative group">내적 계산<div id=%EB%82%B4%EC%A0%81-%EA%B3%84%EC%82%B0 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%EB%82%B4%EC%A0%81-%EA%B3%84%EC%82%B0 aria-label=Anchor>#</a></span></h3><p>일반적인 행렬곱을 계산해도 되지만 one-hot vector의 특성 상, 한 개 성분만이 1을 가지기 때문에 특정 index의 값만 취하게 된다.</p><p>예를 들면 위 그림에서 W1와 x를 곱할 때, x의 2번째 성분만이 1이기 때문에 W1에서 2번째 column만을 취하게 된다.</p><p>이러한 성질을 활용해서, one-hot vector를 곱할 때는 행렬곱을 수행하지 않고 특정 index의 값만을 취하는 형태로 연산이 발생한다.</p><p>W2는 Vocabulary의 수만큼 row vector를 가질 것이다. 실제로 3개의 row를 가지고 있다. row의 차원은 W1과 내적이 가능하도록 2가 될 것이다.</p><blockquote><p><strong>Ground truth</strong>
실제 값을 의미한다. 기상학에서 쓰이던 용어인데, 인공위성과 같이 멀리석 관측한 데이터가 아니라 실제 지상에서 관측한 값을 지칭할 때 쓰던 용어다.
기계 학습에서는 y hat이 아니라 학습 데이터로 주어지는 실제 y 값이라고 생각하면 된다.</p></blockquote><blockquote><p><strong>logits</strong>
sigmoid와 역함수 관계에 있는 함수. 출력이 −∞ ~ +∞다.
ref: <a href=https://velog.io/@gwkoo/logit-sigmoid-softmax%EC%9D%98-%EA%B4%80%EA%B3%84 target=_blank>https://velog.io/@gwkoo/logit-sigmoid-softmax%EC%9D%98-%EA%B4%80%EA%B3%84</a></p></blockquote><p>$W_2(W_1x)$의 값이 ground truth와 일치하게 하려면 ground truth가 1인 3번째 index에서 logits 값이 무한대고 나머지에서는 logits 값이 -무한대여야할 것이다.</p><h4 class="relative group">이해 못 한 점<div id=%EC%9D%B4%ED%95%B4-%EB%AA%BB-%ED%95%9C-%EC%A0%90 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%EC%9D%B4%ED%95%B4-%EB%AA%BB-%ED%95%9C-%EC%A0%90 aria-label=Anchor>#</a></span></h4><p>W1와 W2에 대한 연산이 벡터 간의 유사도를 측정하는 것과 같다고도 하셨는데 무슨 말인지 모르겠다..</p><h3 class="relative group">Property of Word2Vec<div id=property-of-word2vec class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#property-of-word2vec aria-label=Anchor>#</a></span></h3><p>Word2Vect는 단어들간의 의미론적 관계를 vector들 간의 관계에 잘 학습해준다.
![](/assets/images/Word Embedding/1e262f45-bd01-472b-964c-601113b61db0-image.png)</p><p>위 그림은 Word2Vec을 통해 학습된 단어들의 vector다. 서로 비슷한 관계에 있는 벡터들 간의 관계(벡터들 간의 차이)는 같은 방향성을 가지는 것을 알 수 있다.</p><h3 class="relative group">Word2Vec 한글<div id=word2vec-%ED%95%9C%EA%B8%80 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#word2vec-%ED%95%9C%EA%B8%80 aria-label=Anchor>#</a></span></h3><p><a href="https://word2vec.kr/search/?query=%ED%95%9C%EA%B5%AD-%EC%84%9C%EC%9A%B8%2B%EB%8F%84%EC%BF%84" target=_blank>https://word2vec.kr/search/?query=%ED%95%9C%EA%B5%AD-%EC%84%9C%EC%9A%B8%2B%EB%8F%84%EC%BF%84</a></p><p>![](/assets/images/Word Embedding/a94e074e-e8f6-428f-906b-529fdb58091c-image.png)</p><p>Word2Vec을 한글에서 구현한 예제이다. 쿼리문은 다음과 같이 사용된다.
한국-서울은 나라와 수도 간의 관계를 나타내도록 해준다. 그리고 이것에 도쿄를 더하면 나라와 수도 간의 관계를 도쿄에 적용시켜주고 그에 대한 결과를 보여준다.</p><h3 class="relative group">Intrusion Detection<div id=intrusion-detection class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#intrusion-detection aria-label=Anchor>#</a></span></h3><p>여러 단어가 주어졌을 때, 나머지 단어와 가장 의미가 상이한 단어를 찾는 task. Word2Vec을 통해 Word Embedding 결과를 구해서 해결할 수 있다.</p><p>특정 단어에 대한 나머지 단어들의 Euclidian distance를 구하고 평균을 낸다. 이러한 과정을 모든 단어에 대해 반복하고 거리의 평균이 가장 큰 단어를 구하면 된다.</p><h3 class="relative group">Application of Word2Vec<div id=application-of-word2vec class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#application-of-word2vec aria-label=Anchor>#</a></span></h3><p>본래 단어의 의미를 찾기 위한 방법론이지만, Word Embedding 결과를 쉽게 뽑아주는 task이다. 따라서 단어를 벡터로 변환해야 되는 다른 nlp 방법론에서도 유용하게 많이 사용한다.</p><ul><li>Word simliarity</li><li>Machine translation<ul><li>서로 다른 언어에서 같은 의미를 가지는 단어들이 쉽게 align될 수 있게 해준다.</li></ul></li><li>PoS tagging</li><li>NER</li><li>Sentiment analysis<ul><li>단어들의 긍정, 부정을 쉽게 표현할 수 있게 해준다.</li></ul></li><li>Clustering</li><li>Semnatic lexicon building</li><li>Image captioning</li></ul><h2 class="relative group">GloVe<div id=glove class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#glove aria-label=Anchor>#</a></span></h2><p>Word2Vec과 함께 많이 사용되는 Word Embedding 방법론.</p><p>Word2Vec과의 가장 큰 차이점은, 학습 데이터 내에서 한 단어 쌍이 하나의 windows에서 동시에 출현한 빈도 수를 미리 모두 계산한다. 이것을 $P_{ij}$라고 하자.</p><p>![](/assets/images/Word Embedding/42dd8894-fed3-494d-a1eb-feab9605c113-image.png)</p><p>GloVe의 object(loss) function은 위와 같다.</p><ul><li>$u_i$ = input word embedding vector</li><li>$v_j$ = output word embedding vector</li><li>$P_{ij}$ = i, j 두 단어가 한 window 내에서 동시에 몇 번 존재하는가.</li></ul><p>선형대수적인 관점에서, 추천시스템 알고리즘인 co-occurrence low rank matrix factorization로도 이해할 수 있다.</p><h3 class="relative group">장점<div id=%EC%9E%A5%EC%A0%90 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%EC%9E%A5%EC%A0%90 aria-label=Anchor>#</a></span></h3><p>중복되는 계산을 줄일 수 있다. 가령, study와 math가 동시에 많이 존재한다면 Word2Vec은 두 단어 간의 관계에 대해 그냥 많이 학습한다. 하지만 GloVe는 미리 두 단어의 동시 존재성에 대해서 알고 있다.</p><p>따라서 위 수식에서 study와 math의 경우 내적 값에 큰 값을 빼주면서 학습을 더 빨리 할 수 있게 해준다.</p><p>또한 더 적은 데이터에 대해서도 잘 작동한다.</p><h3 class="relative group">예시<div id=%EC%98%88%EC%8B%9C class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%EC%98%88%EC%8B%9C aria-label=Anchor>#</a></span></h3><p>![](/assets/images/Word Embedding/83e4d75b-78c7-483c-87e8-0044e3074d79-image.png)</p><p>성별만 다르고 의미가 같은 단어에 대해 GloVe를 수행한 결괄르 PCA로 찍어본 결과다. 성별의 차이가 일정한 크기와 방향을 가진다는 것을 알 수 있다.</p><p>![](/assets/images/Word Embedding/41d2c1e0-3829-49f8-89d0-fc03c6e756c6-image.png)</p><p>형용사의 comparative, superlative 또한 크기와 방향성을 학습한다!</p><h3 class="relative group">Pre trained model<div id=pre-trained-model class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#pre-trained-model aria-label=Anchor>#</a></span></h3><p><a href=https://nlp.stanford.edu/projects/glove/ target=_blank>https://nlp.stanford.edu/projects/glove/</a></p><p>wikipedia, crawling, twitter에서 수집한 단어들에 대한 pre trained 모델을 배포해준다.
![](/assets/images/Word Embedding/7216a42a-d6d0-4828-aecd-83a9aa09bd6f-image.png)</p><ul><li>uncased: 대소문자가 구별된 단어라도 같은 단어로 취급</li><li>cased: 대소문자가 구별된 단어를 다른 단어로 취급</li><li>dimesion: 입출력 word 벡터의 dimension</li></ul></div></div><script>var oid="views_posts/ML/2021-09-06-Word Embedding.md",oid_likes="likes_posts/ML/2021-09-06-Word Embedding.md"</script><script type=text/javascript src=/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/posts/ml/2021-09-06-%EC%B2%AB%EB%B2%88%EC%A7%B8-ai-competition-%EB%A7%88%EB%AC%B4%EB%A6%AC/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">첫번째 Ai Competition 마무리</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2021-09-06T11:01:54+00:00>6 September 2021</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/posts/ml/2021-09-06-nlp-%EC%A0%84%EC%B2%98%EB%A6%AC/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">NLP 전처리</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2021-09-06T23:56:25+00:00>6 September 2021</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/tags/ title=Tags>Tags</a></li><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/categories/ title=Categories>Categories</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Sungho Park (gigio1023)</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://gigio1023.github.io/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>